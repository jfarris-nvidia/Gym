swerl_llm_judge:
  resources_servers:
    swerl_llm_judge:
      entrypoint: app.py
      domain: coding
      verified: false
      description: SWE-style multiple-choice LLM-judge tasks scored via <solution>...</solution> choice.
      value: Improve SWE capabilities useful for benchmarks like SWE-bench
      dataset_name: SWE-RL-llm-judge
swerl_llm_judge_simple_agent:
  responses_api_agents:
    simple_agent:
      entrypoint: app.py
      resources_server:
        type: resources_servers
        name: swerl_llm_judge
      model_server:
        type: responses_api_models
        name: policy_model
      datasets:
      - name: train
        type: train
        jsonl_fpath: resources_servers/swerl_llm_judge/data/train.jsonl
        gitlab_identifier:
          dataset_name: swe_rl_llm_judge
          version: 0.0.1
          artifact_fpath: train.jsonl
        license: MIT
      - name: validation
        type: validation
        jsonl_fpath: resources_servers/swerl_llm_judge/data/validation.jsonl
        gitlab_identifier:
          dataset_name: swe_rl_llm_judge
          version: 0.0.1
          artifact_fpath: validation.jsonl
        license: MIT
      - name: example
        type: example
        jsonl_fpath: resources_servers/swerl_llm_judge/data/example.jsonl


